}
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date))
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
tidy_docs <- meta |>
tidy()
meta
tidy_docs <- meta |>
unnest_tokens(sentence, words, token = "words")
tidy_docs <- meta |>
unnest_tokens(sentence)
tidy_docs <- meta |>
unnest_tokens(sentence, word)
tidy_docs <- meta |>
unnest_tokens(sentence, word, token = "word")
meta
meta |>
unnest_tokens(word, sentence)
meta |>
unnest_tokens(word, sentence) |>
count(word)
meta |>
unnest_tokens(word, sentence) |>
count(word) |>
sort(n, decreasing = FALSE)
meta |>
unnest_tokens(word, sentence) |>
count(word) |>
sort(n, decr = FALSE)
meta |>
unnest_tokens(word, sentence) |>
count(word, sort = TRUE)
custom_stop <- c("indigenous",
"_mcgill",
"_mowhawkmothers",
"mothers",
"mohawk",
"_rvh",
"Kahentinetha",
"kahnistensera",
"kwetiio",
"victoria",
"_sqi")
meta
meta |>
unnest_tokens(word, sentence)|>
count(word, sort = TRUE)
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
ucp = TRUE,
onlycharacter = TRUE,
customstopwords = custom_stop
language = "en")
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
ucp = TRUE,
onlycharacter = TRUE,
customstopwords = custom_stop,
language = "en")
docs <- temp$documents
vocab <- temp$vocab
meta <- temp$meta
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
rm(files, temp)
model <- stm(documents = docs, vocab = vocab, K = 9,
prevalence = ~ s(date) + indigenous + corporate + student, data = meta)
estimate <- estimateEffect(formula = 1:K ~ date + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs) |>
tidy() |>
filter(term != "(Intercept)")
estimate <- estimateEffect(formula = 1:9 ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs) |>
tidy() |>
filter(term != "(Intercept)")
estimate <- estimateEffect(formula = 1:9 ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs)
estimate
estimate |>
tidy()
estimate |>
tidy() |>
filter(term != "(Intercept)")
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
filter(p.value <= 0.05)
findThoughts(model, texts = meta$sentence, n = 3, meta = meta)
labelTopics(model, topics = c(4,8,9,5), n = 5)
meta
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
meta <- map_dfr(files, process_file)
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date))
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
meta |>
unnest_sentences(sentence, sentence)
meta
meta |>
unnest_sentences(sentence, sentence)
745 - 1178
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date)) |>
unnest_sentences(sentence, sentence)
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
```{r}
custom_stop <- c("indigenous",
"_mcgill",
"_mowhawkmothers",
"mothers",
"mohawk",
"_rvh",
"Kahentinetha",
"kahnistensera",
"kwetiio",
"victoria",
"_sqi")
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
ucp = TRUE,
onlycharacter = TRUE,
customstopwords = custom_stop,
language = "en")
docs <- temp$documents
vocab <- temp$vocab
meta <- temp$meta
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
rm(files, temp)
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
lower.thresh = 100,
upper.thresh = 1000,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
lower.thresh = 10,
upper.thresh = 1000,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 1000,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 900,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
temp
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 800,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 700,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 600,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 500,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 400,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 300,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 200,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 250,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 240,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 230,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 220,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 210,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 200,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 205,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 206,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 700,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
lower.thresh = 1,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
rm(files, temp)
rm(custom_stop, process_file)
model <- stm(documents = docs, vocab = vocab, K = 9,
prevalence = ~ s(date) + indigenous + corporate + student, data = meta)
estimate <- estimateEffect(formula = 1:9 ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
filter(p.value <= 0.05)
library(ggplot2)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
filter(p.value <= 0.05) |>
ggplot(aes(x = statistic)) +
geom_histogram()
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic)) +
geom_histogram()
estimate |>
tidy() |>
filter(term != "(Intercept)")
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic)) +
geom_histogram(bins = 10)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic)) +
geom_histogram(bins = 20)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.05) |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.01) |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.001) |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.001)
large_effects <- estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.001)
large_effects
large_effects |>
print(n=33)
large_effects |>
arrange(statistic)
findThoughts(model, texts = meta$sentence, n = 3, meta = meta)
meta <- map_dfr(files, process_file)
library(gtools)
v <- c("a", "aa", "à", set = FALSE)
v <- c("a", "aa", "à")
combinations(n, r, v, set = FALSE)
n <- 3 # size of sorce vector
r <- 3 # size of target vectors
combinations(n, r, v, set = FALSE)
combinations(n, r, v, repeats = TRUE)
permutations(n, r, v, repeats=T)
library(tibble)
tibble(permutations(n, r, v, repeats = T))
perms <- permutations(n, r, v, repeats=T)
tibble(a = perms[,1], aa = perms[,2], à = [perms,3])
tibble(a = perms[,1], aa = perms[,2], à = perms[,3])
alophone_assignments <- tibble(a = perms[,1], aa = perms[,2], à = perms[,3])
library(tidyverse)
alophone_assignments |>
filter(a != aa)
alophone_assignments |>
filter(a != aa) |>  # a and aa are contrastive (eliminates 9 permutations)
filter(a != "aa")
alophone_assignments |>
filter(a != aa & a != "aa" & aa != "a")  # a and aa are contrastive (eliminates 9 permutations)
kable(perms, format = "latex", caption = "This rows in this table represent all of the possible mappings of the allophones a, aa, and à (the collunns) to phonemes a, aa, and à. Each cell in this table represents which phoneme the segment at the top of the collumn belongs to.")
knitr::kable(perms, format = "latex", caption = "This rows in this table represent all of the possible mappings of the allophones a, aa, and à (the collunns) to phonemes a, aa, and à. Each cell in this table represents which phoneme the segment at the top of the collumn belongs to.")
library(lubridate)
library(dplyr)
library(purrr)
library(yaml)
library(stm)
library(tidytext)
set.seed(117)
files <- list.files("data", pattern = "*.txt", full.names = TRUE)
files
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
mcgill <- if ("mcgill" %in% fm$tags) {"mcgill"} else {"non-mcgill"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
mcgill = rep(mcgill, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
meta <- map_dfr(files, process_file)
library(purrr)
library(yaml)
library(dplyr)
library(lubridate)
files <- list.files("data", pattern = "*.txt", full.names = TRUE)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
mcgill <- if ("mcgill" %in% fm$tags) {"mcgill"} else {"non-mcgill"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
mcgill = rep(mcgill, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
meta <- map_dfr(files, process_file)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
mcgill <- if ("mcgill" %in% fm$tags) {"mcgill"} else {"non-mcgill"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[7:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
mcgill = rep(mcgill, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
```{r clean_and_import_data}
meta <- map_dfr(files, process_file)
