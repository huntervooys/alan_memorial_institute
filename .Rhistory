content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date))
meta |>
count(indigenous)
meta |>
count(corporate)
meta |>
count(student)
meta |>
count(publisher)
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
lowercase = TRUE,
removenumbers = TRUE,
removepunctuation = TRUE,
removestopwords = TRUE,
language = "en")
docs <- temp$documents
vocab <- temp$vocab
meta <- temp$meta
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
K <- seq(3,15,1)
kresult <- searchK(documents = docs,
vocab = vocab, K,
prevalence= ~ s(date) + indigenous + corporate + student,
data=meta)
model <- stm(documents = docs, vocab = vocab, K = K, prevalence = ~ s(date) + indigenous + corporate + student)
model <- stm(documents = docs, vocab = vocab, K = K, prevalence = ~ s(date) + indigenous + corporate + student, data = meta)
## picking k = 5
K <- 5
model <- stm(documents = docs, vocab = vocab, K = K, prevalence = ~ s(date) + indigenous + corporate + student, data = meta)
estimate <- estimateEffect(formula = 1:K ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs) |>
tidy() |>
filter(term != "(Intercept)")
## more likely to appear in student documents
## seurity guard
# 4
## down at 2, surge at 3 and 4
## much higher in indigenous and corporate, much lower in student
## colonization, territory, pope, cross
# 5
## low at 3 and 4, and 5, but increasing
## less common in corporate
# thoughts: all about MK Ultra
estimate |>
filter(p.value <= 0.01)
labelTopics(model, topics = ts, n = 10)
set.seed(117)
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
library(lubridate)
library(dplyr)
library(purrr)
library(yaml)
library(stm)
library(tidytext)
set.seed(117)
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date))
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
tidy_docs <- meta |>
tidy()
meta
tidy_docs <- meta |>
unnest_tokens(sentence, words, token = "words")
tidy_docs <- meta |>
unnest_tokens(sentence)
tidy_docs <- meta |>
unnest_tokens(sentence, word)
tidy_docs <- meta |>
unnest_tokens(sentence, word, token = "word")
meta
meta |>
unnest_tokens(word, sentence)
meta |>
unnest_tokens(word, sentence) |>
count(word)
meta |>
unnest_tokens(word, sentence) |>
count(word) |>
sort(n, decreasing = FALSE)
meta |>
unnest_tokens(word, sentence) |>
count(word) |>
sort(n, decr = FALSE)
meta |>
unnest_tokens(word, sentence) |>
count(word, sort = TRUE)
custom_stop <- c("indigenous",
"_mcgill",
"_mowhawkmothers",
"mothers",
"mohawk",
"_rvh",
"Kahentinetha",
"kahnistensera",
"kwetiio",
"victoria",
"_sqi")
meta
meta |>
unnest_tokens(word, sentence)|>
count(word, sort = TRUE)
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
ucp = TRUE,
onlycharacter = TRUE,
customstopwords = custom_stop
language = "en")
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
ucp = TRUE,
onlycharacter = TRUE,
customstopwords = custom_stop,
language = "en")
docs <- temp$documents
vocab <- temp$vocab
meta <- temp$meta
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
rm(files, temp)
model <- stm(documents = docs, vocab = vocab, K = 9,
prevalence = ~ s(date) + indigenous + corporate + student, data = meta)
estimate <- estimateEffect(formula = 1:K ~ date + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs) |>
tidy() |>
filter(term != "(Intercept)")
estimate <- estimateEffect(formula = 1:9 ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs) |>
tidy() |>
filter(term != "(Intercept)")
estimate <- estimateEffect(formula = 1:9 ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs)
estimate
estimate |>
tidy()
estimate |>
tidy() |>
filter(term != "(Intercept)")
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
filter(p.value <= 0.05)
findThoughts(model, texts = meta$sentence, n = 3, meta = meta)
labelTopics(model, topics = c(4,8,9,5), n = 5)
meta
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
meta <- map_dfr(files, process_file)
files <- list.files("documents", pattern = "*.txt", full.names = TRUE)
process_file <- function(file) {
content <- readLines(file)
content <- gsub("@", "_", content)
fm <- yaml::yaml.load(content[1:8])
indigenous <- if ("indigenous" %in% fm$tags) {"indigenous"} else {"non-indigenous"}
corporate <- if ("news, corporate" %in% fm$tags) {"corporate"} else {"non-corporate"}
student <- if ("news, student" %in% fm$tags) {"student"} else {"non-student"}
date <- mdy(fm$date)
publisher <- fm$publisher
if (length(content) >= 10) {
sentences <- content[10:length(content)]
data.frame(
date = rep(date, length(sentences)),
indigenous = rep(indigenous, length(sentences)),
corporate = rep(corporate, length(sentences)),
student = rep(student, length(sentences)),
publisher = rep(publisher, length(sentences)),
sentence = sentences
)
} else {
NULL
}
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date))
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
meta |>
unnest_sentences(sentence, sentence)
meta
meta |>
unnest_sentences(sentence, sentence)
745 - 1178
meta <- map_dfr(files, process_file)
meta$date <- as.numeric(meta$date)
meta$publisher <- tolower(meta$publisher)
meta <- meta |>
filter(!is.na(date)) |>
unnest_sentences(sentence, sentence)
meta$indigenous <- factor(meta$indigenous)
meta$corporate <- factor(meta$corporate)
meta$student <- factor(meta$student)
meta$publisher <- factor(meta$publisher)
```{r}
custom_stop <- c("indigenous",
"_mcgill",
"_mowhawkmothers",
"mothers",
"mohawk",
"_rvh",
"Kahentinetha",
"kahnistensera",
"kwetiio",
"victoria",
"_sqi")
temp <- textProcessor(documents = meta$sentence,
metadata = meta,
ucp = TRUE,
onlycharacter = TRUE,
customstopwords = custom_stop,
language = "en")
docs <- temp$documents
vocab <- temp$vocab
meta <- temp$meta
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
rm(files, temp)
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
lower.thresh = 100,
upper.thresh = 1000,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
lower.thresh = 10,
upper.thresh = 1000,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 1000,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 900,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
temp
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 800,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 700,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 600,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 500,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 400,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 300,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 200,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 250,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 240,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 230,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 220,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 210,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 200,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 205,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 206,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
upper.thresh = 700,
verbose = TRUE) ## lower and upper thresh not set
temp <- prepDocuments(documents = docs,
vocab = vocab,
meta = meta,
lower.thresh = 1,
verbose = TRUE) ## lower and upper thresh not set
docs <- temp$documents
meta <- temp$meta
vocab <- temp$vocab
rm(files, temp)
rm(custom_stop, process_file)
model <- stm(documents = docs, vocab = vocab, K = 9,
prevalence = ~ s(date) + indigenous + corporate + student, data = meta)
estimate <- estimateEffect(formula = 1:9 ~ s(date) + indigenous + corporate + student,
stmobj = model,
metadata = meta,
documents = docs)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
filter(p.value <= 0.05)
library(ggplot2)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
filter(p.value <= 0.05) |>
ggplot(aes(x = statistic)) +
geom_histogram()
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic)) +
geom_histogram()
estimate |>
tidy() |>
filter(term != "(Intercept)")
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic)) +
geom_histogram(bins = 10)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic)) +
geom_histogram(bins = 20)
estimate |>
tidy() |>
filter(term != "(Intercept)") |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.05) |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.01) |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.001) |>
ggplot(aes(x = statistic, y = statistic)) +
geom_point()
estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.001)
large_effects <- estimate |>
tidy() |>
filter(term != "(Intercept)", p.value <= 0.001)
large_effects
large_effects |>
print(n=33)
large_effects |>
arrange(statistic)
findThoughts(model, texts = meta$sentence, n = 3, meta = meta)
meta <- map_dfr(files, process_file)
