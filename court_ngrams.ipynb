{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argument_plan.txt\n",
      "affidavit_philippe.txt\n",
      "affidavit_lana_ponting.txt\n",
      "settlement_agreement.txt\n",
      "affidavit_kahentientha.txt\n",
      "originating_application.txt\n"
     ]
    }
   ],
   "source": [
    "###### from chat gpt\n",
    "directory_path = 'data/text_files'\n",
    "\n",
    "# List all files in the directory\n",
    "file_list = [file for file in os.listdir(directory_path) if file.endswith('.txt')]\n",
    "\n",
    "# Dictionary to store file content\n",
    "file_contents = {}\n",
    "\n",
    "# Iterate through each file and read line by line\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = [line.strip() for line in file]\n",
    "        file_contents[file_name] = lines\n",
    "        \n",
    "## this last part is mine\n",
    "doc_names = [name for name in file_contents]\n",
    "for name in doc_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "\n",
    "nothing in this section is ai-generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing: argument_plan.txt\n",
      "first 15 tokens from argument_plan.txt\n",
      " ['the', 'special', 'interlocutor', 'respectfully', 'submits', 'that', 'a', 'determination', 'of', 'the', 'issues', 'in', 'respect', 'of'] \n",
      "\n",
      "tokenizing: affidavit_philippe.txt\n",
      "first 15 tokens from affidavit_philippe.txt\n",
      " ['i', 'have', 'been', 'asked', 'by', 'the', 'kanien', 'kakahnistenser', 'a', 'mohawkmothers', 'to', 'produce', 'a', 'report'] \n",
      "\n",
      "tokenizing: affidavit_lana_ponting.txt\n",
      "first 15 tokens from affidavit_lana_ponting.txt\n",
      " ['my', 'name', 'is', 'lana', 'ponting', 'i', 'was', 'a', 'typical', 'rebellious', 'teenager', 'with', 'a', 'new'] \n",
      "\n",
      "tokenizing: settlement_agreement.txt\n",
      "first 15 tokens from settlement_agreement.txt\n",
      " ['whereas', 'an', 'order', 'was', 'issued', 'by', 'justice', 'moore', 'on', 'october', 'inviting', 'the', 'parties', 'to'] \n",
      "\n",
      "tokenizing: affidavit_kahentientha.txt\n",
      "first 15 tokens from affidavit_kahentientha.txt\n",
      " ['i', 'have', 'been', 'nurtured', 'in', 'the', 'kaianere', 'wa', 'greatpeace', 'from', 'the', 'beginning', 'of', 'my'] \n",
      "\n",
      "tokenizing: originating_application.txt\n",
      "first 15 tokens from originating_application.txt\n",
      " ['the', 'wa', 'great', 'law', 'of', 'peace', 'has', 'been', 'the', 'original', 'constitution', 'of', 'the', 'original'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "def count_ngrams(corpus, n):\n",
    "    ngrams = Counter()\n",
    "    \n",
    "    for document, words in corpus.items():\n",
    "        \n",
    "        while len(words) >= n:\n",
    "            for i in range(len(words) - n + 1):\n",
    "                ngram = \" \".join(words[i:i+n])\n",
    "                ngrams[ngram] += 1\n",
    "    return ngrams\n",
    "\n",
    "corpus = dict()\n",
    "for document in doc_names:\n",
    "    \n",
    "    print(f\"tokenizing: {document}\")\n",
    "    doc_lines = file_contents[document]\n",
    "    token_lines = [word_tokenize(line) for line in doc_lines if line != \"\"]\n",
    "    tokens = [token.lower() for line in token_lines for token in line if token.isalpha()]\n",
    "    corpus[document] = tokens\n",
    "\n",
    "    first_tokens = corpus[document][:14]\n",
    "    print(f\"first 15 tokens from {document}\\n\",first_tokens, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1938),\n",
       " ('of', 1002),\n",
       " ('and', 796),\n",
       " ('to', 682),\n",
       " ('in', 551),\n",
       " ('a', 444),\n",
       " ('that', 331),\n",
       " ('was', 269),\n",
       " ('on', 256),\n",
       " ('i', 250),\n",
       " ('as', 218),\n",
       " ('for', 207),\n",
       " ('exhibit', 195),\n",
       " ('by', 162),\n",
       " ('is', 155)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = count_ngrams(corpus, 1)\n",
    "\n",
    "words.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the', 321),\n",
       " ('in the', 159),\n",
       " ('to the', 130),\n",
       " ('and the', 93),\n",
       " ('on the', 84),\n",
       " ('at the', 79),\n",
       " ('by the', 61),\n",
       " ('that the', 58),\n",
       " ('for the', 55),\n",
       " ('the allan', 50),\n",
       " ('the ami', 49),\n",
       " ('memorial institute', 47),\n",
       " ('from the', 42),\n",
       " ('i was', 41),\n",
       " ('allan memorial', 40)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = count_ngrams(corpus, 2)\n",
    "\n",
    "bigrams.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('allan memorial institute', 37),\n",
       " ('the allan memorial', 34),\n",
       " ('royal victoria hospital', 33),\n",
       " ('the royal victoria', 25),\n",
       " ('the department of', 14),\n",
       " ('the indian act', 13),\n",
       " ('the grounds of', 13),\n",
       " ('at the ami', 13),\n",
       " ('grounds of the', 12),\n",
       " ('at the allan', 12),\n",
       " ('as well as', 12),\n",
       " ('part of the', 11),\n",
       " ('of the allan', 11),\n",
       " ('of the ami', 11),\n",
       " ('panel on indian', 11)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = count_ngrams(corpus, 3)\n",
    "\n",
    "trigrams.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the allan memorial institute', 32),\n",
       " ('the royal victoria hospital', 25),\n",
       " ('the grounds of the', 11),\n",
       " ('of the allan memorial', 11),\n",
       " ('panel on indian research', 11),\n",
       " ('as appears from a', 10),\n",
       " ('royal victoria hospital and', 9),\n",
       " ('of national health and', 9),\n",
       " ('national health and welfare', 9),\n",
       " ('the panel on indian', 9),\n",
       " ('the city of montreal', 9),\n",
       " ('appears from a copy', 9),\n",
       " ('from a copy of', 9),\n",
       " ('grounds of the allan', 8),\n",
       " ('at the allan memorial', 8)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourgrams = count_ngrams(corpus, 4)\n",
    "\n",
    "fourgrams.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the allan memorial institute', 9),\n",
       " ('of national health and welfare', 9),\n",
       " ('the panel on indian research', 9),\n",
       " ('as appears from a copy', 9),\n",
       " ('appears from a copy of', 9),\n",
       " ('the grounds of the allan', 8),\n",
       " ('grounds of the allan memorial', 8),\n",
       " ('at the allan memorial institute', 8),\n",
       " ('the royal victoria hospital and', 8),\n",
       " ('department of national health and', 8),\n",
       " ('the kanien keha ka kahnistensera', 7),\n",
       " ('on the grounds of the', 6),\n",
       " ('the department of national health', 6),\n",
       " ('unmarked graves and burial sites', 5),\n",
       " ('the truth and reconciliation commission', 5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fivegrams = count_ngrams(corpus, 5)\n",
    "\n",
    "fivegrams.most_common(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
